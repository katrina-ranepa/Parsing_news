import requests
from bs4 import BeautifulSoup
import json

# URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
url = "https://web.archive.org/web/20230903112115/https://iz.ru/news"

# –ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
news_by_category = {}

# –ò—â–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –±–ª–æ–∫–∏
news_items = soup.find_all("div", class_="node__cart__item")

for item in news_items:
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    category_div = item.find("div", class_="node__cart__item__category_news")
    if category_div:
        category_link = category_div.find("a")
        if category_link:
            category = category_link.get_text().strip()
        else:
            category = category_div.get_text().strip()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
        title_div = item.find("div", class_="node__cart__item__inside__info__title")
        link_tag = item.find("a", href=True)

        if title_div and link_tag:
            title = title_div.get_text().strip()
            link = link_tag["href"]

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É –≤ –∞–±—Å–æ–ª—é—Ç–Ω—É—é
            if link.startswith("/"):
                link = f"https://iz.ru{link}"

            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ—Å—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            if category not in news_by_category:
                news_by_category[category] = []

            news_item = {"title": title, "link": link}

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
            if news_item not in news_by_category[category]:
                news_by_category[category].append(news_item)

# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
print("–ù–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
print("=" * 60)

for category, news_list in news_by_category.items():
    print(f"\n{category.upper()}:")
    print("-" * 40)
    for i, news in enumerate(news_list, 1):
        print(f"{i}. {news['title']}")
        print(f"   üîó {news['link']}")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON —Ñ–∞–π–ª
with open("iz_news.json", "w", encoding="utf-8") as f:
    json.dump(news_by_category, f, ensure_ascii=False, indent=2)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
total_categories = len(news_by_category)
total_news = sum(len(news_list) for news_list in news_by_category.values())

print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ iz_news.json")
print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {total_categories} –∫–∞—Ç–µ–≥–æ—Ä–∏–π, {total_news} –Ω–æ–≤–æ—Å—Ç–µ–π")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
print("\nüìà –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π:")
for category, news_list in news_by_category.items():
    print(f"   {category}: {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
